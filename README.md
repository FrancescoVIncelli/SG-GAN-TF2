# SG-GAN-TF2
The project shows the improvements in semantic segmentation on a dataset of real-world urban images for autonomouse driving task, using recent Generative Adversarial Network model architectures (such as Grad-GAN and Pix2Pix) which can produce better results against the traditional fully-connected and convolutional discriminative models.  

### Dataset
The images used to train the models are extracted form [The Cityscapes Dataset](https://www.cityscapes-dataset.com/), a large-scale dataset that contains a diverse set of stereo video sequences recorded in street scenes.  
The whole dataset contains images sequences acquired in urban scenarios from 50 different cities, with high quality pixel-level annotations of 5 000 frames in addition to a larger set of 20 000 weakly annotated frames.

### Installation Procedure

### File Structure

### Documentation

### Execution of the code

### Limitations
